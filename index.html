<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="SOCIAL MEDIA TITLE TAG"/>
  <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG"/>
  <meta property="og:url" content="URL OF THE WEBSITE"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>ICGAN: AN IMPLICIT CONDITIONING METHOD FOR INTERPRETABLE FEATURE CONTROL
    OF NEURAL AUDIO SYNTHESIS</title>
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/bulma/0.9.3/css/bulma.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">
  
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
  
  
</head>
<body>

  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">ICGAN</h1>
            <h2 class="">AN IMPLICIT CONDITIONING METHOD FOR INTERPRETABLE FEATURE CONTROL
              OF NEURAL AUDIO SYNTHESIS</h2>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="FIRST AUTHOR PERSONAL LINK" target="_blank">Yunyi Liu</a>,</span>
                <span class="author-block">
                  <a href="SECOND AUTHOR PERSONAL LINK" target="_blank">Craig Jin</a>,</span>
                  </div>

                  <div class="is-size-5 publication-authors">
                    <span class="author-block">University of Sydney<br>Electrical and Information Engineering</span>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- Arxiv PDF link -->
                      <span class="link-block">
                        <a href="https://arxiv.org/pdf/<ARXIV PAPER ID>.pdf" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>

                  <!-- Github link -->
                  <span class="link-block">
                    <a href="https://github.com/Reinliu/ICGAN" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Architecture image-->
<section class="hero Architecture">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <img src="static/ICGAN/Architecture.png" id="tree" alt="Architecture Image" style="width: 100%;">
      <h2 class="subtitle has-text-centered">
        ICGAN architecture
      </h2>
    </div>
  </div>
</section>
<!-- End Architecture image -->

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Neural audio synthesis methods can achieve high-fidelity and realistic sound generation by utilizing 
            deep generative models. However, such models typically fail to provide convenient or interpretable 
            controls to guide the sound generation, especially with regard to sounds that are hard to describe by 
            words. We propose an implicit conditioning method to achieve smooth interpolation between different classes of 
            sounds with discrete labels. As shown in our architecture, our generator is conditioned on a vector sampled 
            from a Gaussian distribution with mean and variance parameterized from the encoder. The encoder learns
            the categorical information from the input Mel spectrograms and guides the generator in an implicit way. Our technique creates a 
            continuous conditioning space that enables timbre manipulation without relying on explicit labels. 
            We further introduce an evaluation metric to explore controllability and demonstrate that our approach 
            is effective in enabling a degree of controlled variation of different sound effects for same-class 
            and cross-class sounds.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->


<!-- Interpolation -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Interpolation</h2>
        <div class="content has-text-justified">
          <p>
            We interpolate our conditioning space between two classes of sounds, one starting a value at 0 while
            another starting at 1. We show the output probabilities returned from the fine-tuned PANNs classifier.
          </p>
        </div>
      </div>
    </div>
  </div>

  <!-- Footsteps -->
<section class="section">
  <h1 class="section-title">Footsteps</h1>

<div class="images-audio-container">
  <figure>
      <figure class="image">
      <img src="static/ICGAN/interpolation/footstep/footstep-class-0-3-22-30.png" alt="Image 1">
      </figure>
  </figure>
  
  <figure>
      <figure class="image">
      <img src="static/ICGAN/interpolation/footstep/footstep-class-0-4-6,9.png" alt="Image 2">
      </figure>
  </figure>
  
  <figure>
    <figure class="image">
    <img src="static/ICGAN/interpolation/footstep/footstep-class-6-8-39-43.png" alt="Image 2">
    </figure>
</figure>

<figure>
  <figure class="image">
  <img src="static/ICGAN/interpolation/footstep/footstep-ht-class-1-4-6-7.png" alt="Image 2">
  </figure>
</figure>

<figure>
  <figure class="image">
  <img src="static/ICGAN/interpolation/footstep/hits-ft-class-3-7-60-80.png" alt="Image 2">
  </figure>
</figure>
</div>
</section>
<!-- Footsteps -->


  <!-- Guns -->
  <section class="section">
    <h1 class="section-title">Guns</h1>
  
  <div class="images-audio-container">
    <figure>
        <figure class="image">
        <img src="static/ICGAN/interpolation/guns/guns-class-0-3-48.75-50.png" alt="Image 1">
        </figure>
    </figure>
    
    <figure>
        <figure class="image">
        <img src="static/ICGAN/interpolation/guns/guns-class-1-2-45-50.png" alt="Image 2">
        </figure>
    </figure>
    
    <figure>
      <figure class="image">
      <img src="static/ICGAN/interpolation/guns/guns-class-2-6-80-85.png" alt="Image 2">
      </figure>
  </figure>
  
  <figure>
    <figure class="image">
    <img src="static/ICGAN/interpolation/guns/guns-class-3-9-80-85.png" alt="Image 2">
    </figure>
  </figure>
  
  <figure>
    <figure class="image">
    <img src="static/ICGAN/interpolation/guns/guns-class-4-9-51-53.png" alt="Image 2">
    </figure>
  </figure>
  </div>
  </section>
  <!-- Guns -->


    <!-- Hits -->
<section class="section">
  <h1 class="section-title">Hits</h1>

<div class="images-audio-container">
  <figure>
      <figure class="image">
      <img src="static/ICGAN/interpolation/hits/footstep-ht-class-1-5-11-15.png" alt="Image 1">
      </figure>
  </figure>
  
  <figure>
      <figure class="image">
      <img src="static/ICGAN/interpolation/hits/footstep-ht-class-1-6-12-15.png" alt="Image 2">
      </figure>
  </figure>
  
  <figure>
    <figure class="image">
    <img src="static/ICGAN/interpolation/hits/footstep-ht-class-1-7-12-15.png" alt="Image 2">
    </figure>
</figure>

<figure>
  <figure class="image">
  <img src="static/ICGAN/interpolation/hits/footstep-ht-class-1-8-12.5-13.5.png" alt="Image 2">
  </figure>
</figure>

<figure>
  <figure class="image">
  <img src="static/ICGAN/interpolation/hits/hits-class-1-3-82-100.png" alt="Image 2">
  </figure>
</figure>
</div>
</section>
<!-- Hits -->

</section>
<!-- End paper interpolation -->


<!-- In-class sounds -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Generated sounds with implicit conditioning</h2>
        <div class="content has-text-justified">
          <p>
            During the inference stage, we could generate Mel spectrograms by inputting self-defined sampled
            vectors. As the learned sampled vectors are expected to have a mean of 0 when the associated class
            feature is absent and a mean of 1 when the associated class feature is present, we manually set the 
            sampled vectors with 1 at a class dimension and 0 for everywhere else. Below we show the generated 
            Mel spectrograms and transformed sounds conditioned on self-defined vectors.
          </p>
        </div>
      </div>
    </div>
  </div>


<section class="section">
  <h1 class="section-title">Footsteps</h1>

<div class="images-audio-container">
  <figure>
      <figcaption>Reference: Walking on street</figcaption>
      <figure class="image">
      <img src="static/ICGAN/Footstep/footstep-0.png" alt="Image 1">
      </figure>
      <audio controls>
          <source src="static/ICGAN/Footstep/footstep-ref.wav" type="audio/mpeg">
      </audio>
  </figure>
  
  <figure>
      <figcaption>Gravel</figcaption>
      <figure class="image">
      <img src="static/ICGAN/Footstep/footstep-gravel.png" alt="Image 2">
      </figure>
      <audio controls>
          <source src="static/ICGAN/Footstep/footstep-gravel.wav" type="audio/mpeg">
      </audio>
  </figure>
  
  <figure>
    <figcaption>Snow</figcaption>
    <figure class="image">
    <img src="static/ICGAN/Footstep/footstep-snow.png" alt="Image 2">
    </figure>
    <audio controls>
        <source src="static/ICGAN/Footstep/footstep-snow.wav" type="audio/mpeg">
    </audio>
</figure>

<figure>
  <figcaption>Wood</figcaption>
  <figure class="image">
  <img src="static/ICGAN/Footstep/footstep-wood.png" alt="Image 2">
  </figure>
  <audio controls>
      <source src="static/ICGAN/Footstep/footstep-wood.wav" type="audio/mpeg">
  </audio>
</figure>

<figure>
  <figcaption>Concrete</figcaption>
  <figure class="image">
  <img src="static/ICGAN/Footstep/footstep-concrete.png" alt="Image 2">
  </figure>
  <audio controls>
      <source src="static/ICGAN/Footstep/footstep-concrete.wav" type="audio/mpeg">
  </audio>
</figure>
</div>

</section>


<!-- Guns -->

<section class="section">
  <h1 class="section-title">Guns</h1>

<div class="images-audio-container">
  <figure>
      <figcaption>Reference: Canon Explosion</figcaption>
      <figure class="image">
      <img src="static/ICGAN/Guns/gun-0.png" alt="Image 1">
      </figure>
      <audio controls>
          <source src="static/ICGAN/Guns/gun-0.wav" type="audio/mpeg">
      </audio>
  </figure>
  
  <figure>
      <figcaption>Grenade</figcaption>
      <figure class="image">
      <img src="static/ICGAN/Guns/gun-grenade.png" alt="Image 2">
      </figure>
      <audio controls>
          <source src="static/ICGAN/Guns/gun-grenade.wav" type="audio/mpeg">
      </audio>
  </figure>
  
  <figure>
    <figcaption>Ricochet</figcaption>
    <figure class="image">
    <img src="static/ICGAN/Guns/gun-bullet-Ricochet.png" alt="Image 2">
    </figure>
    <audio controls>
        <source src="static/ICGAN/Guns/gun-bullet-Ricochet.wav" type="audio/mpeg">
    </audio>
</figure>

<figure>
  <figcaption>Machine Gun</figcaption>
  <figure class="image">
  <img src="static/ICGAN/Guns/gun-machinegun.png" alt="Image 2">
  </figure>
  <audio controls>
      <source src="static/ICGAN/Guns/gun-machinegun.wav" type="audio/mpeg">
  </audio>
</figure>

<figure>
  <figcaption>Rifle</figcaption>
  <figure class="image">
  <img src="static/ICGAN/Guns/gun-rifle.png" alt="Image 2">
  </figure>
  <audio controls>
      <source src="static/ICGAN/Guns/gun-rifle.wav" type="audio/mpeg">
  </audio>
</figure>
</div>

</section>
<!-- Guns -->


<!-- Hits -->

<section class="section">
  <h1 class="section-title">Hits</h1>

<div class="images-audio-container">
  <figure>
      <figcaption>Reference: Hit Ball</figcaption>
      <figure class="image">
      <img src="static/ICGAN/Hits/hit-ref.png" alt="Image 1">
      </figure>
      <audio controls>
          <source src="static/ICGAN/Hits/hit-ref.wav" type="audio/mpeg">
      </audio>
  </figure>
  
  <figure>
      <figcaption>Hit Melon</figcaption>
      <figure class="image">
      <img src="static/ICGAN/Hits/hit-melon.png" alt="Image 2">
      </figure>
      <audio controls>
          <source src="static/ICGAN/Hits/hit-melon.wav" type="audio/mpeg">
      </audio>
  </figure>
  
  <figure>
    <figcaption>Hit Body</figcaption>
    <figure class="image">
    <img src="static/ICGAN/Hits/hit-body.png" alt="Image 2">
    </figure>
    <audio controls>
        <source src="static/ICGAN/Hits/hit-body.wav" type="audio/mpeg">
    </audio>
</figure>

<figure>
  <figcaption>Hit face</figcaption>
  <figure class="image">
  <img src="static/ICGAN/Hits/hit-face.png" alt="Image 2">
  </figure>
  <audio controls>
      <source src="static/ICGAN/Hits/hit-face.wav" type="audio/mpeg">
  </audio>
</figure>

<figure>
  <figcaption>Hit Bone</figcaption>
  <figure class="image">
  <img src="static/ICGAN/Hits/hit-bone.png" alt="Image 2">
  </figure>
  <audio controls>
      <source src="static/ICGAN/Hits/hit-bone.wav" type="audio/mpeg">
  </audio>
</figure>
</div>

</section>
<!-- Hits -->

</section>
<!-- End in-class sounds -->



<!-- Out-of-class sounds -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Generated sounds with implicit conditioning</h2>
        <div class="content has-text-justified">
          <p>
            During the inference stage, we could generate Mel spectrograms by inputting self-defined sampled
            vectors. As the learned sampled vectors are expected to have a mean of 0 when the associated class
            feature is absent and a mean of 1 when the associated class feature is present, we manually set the 
            sampled vectors with 1 at a class dimension and 0 for everywhere else. 
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End out-of-class sounds -->



<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>BibTex Code Here</code></pre>
    </div>
</section>
<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" 
            target="_blank">Academic Project Page Template</a> which was adopted from the 
            <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            You are free to borrow the of this website, we just ask that you link back to this page in the footer. 
            <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" 
            target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

  </body>
  </html>

  <script>
    document
        .getElementById('select-speaker')
        .addEventListener('change', function () {
            'use strict';
            var targets = document.getElementsByClassName("select-speaker")
            for (let i = 0; i < targets.length; i++) {
                name = "samples/mp3/ted_speakers/" + this.value + "/sample-" + i.toString() + ".mp3"
                targets[i].setAttribute("src", name)
                targets[i].parentElement.load()
            }
    });
    </script>